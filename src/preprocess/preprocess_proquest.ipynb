{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: \\ ^C\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.1.0\n",
      "  latest version: 24.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.5.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\u001b[33mWARNING: Requirement '/home/ec2-user/SageMaker/packages/blingfire-0.1.8.tar.gz' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n",
      "\u001b[0mProcessing /home/ec2-user/SageMaker/packages/blingfire-0.1.8.tar.gz\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ec2-user/SageMaker/packages/blingfire-0.1.8.tar.gz'\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!conda install -y spacy\n",
    "!conda install -y bs4\n",
    "!pip install /home/ec2-user/SageMaker/packages/blingfire-0.1.8.tar.gz\n",
    "!conda install -y pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import spacy\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "# from sentencex import segment\n",
    "from blingfire import text_to_sentences\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nlp = spacy.load('en_core_web_sm')\n",
    "# nlp.add_pipe('sentencizer')\n",
    "# nlp.select_pipes(enable=[\"sentencizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_inflation(line):\n",
    "    pattern = r'\\binflation\\b'\n",
    "    matches = re.search(pattern, line, re.IGNORECASE)\n",
    "    if matches:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_dir = \"data/Historical_News_test_atlanta\"\n",
    "out_dir = \"data\"  # Specify your output directory\n",
    "\n",
    "\n",
    "def process_file(file):\n",
    "    \n",
    "    none_text = 0\n",
    "    total_sents = 0\n",
    "    inflation_sents = 0\n",
    "    \n",
    "    tree = ET.parse(os.path.join(base_data_dir, file))\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    hidden_text_element = root.findall(\".//*[@HTMLContent='true']\")\n",
    "    if hidden_text_element is None or hidden_text_element == []:\n",
    "        none_text += 1\n",
    "        return  none_text, total_sents, [], None, None\n",
    "    \n",
    "    hidden_text_html = \"\"\n",
    "    for el in hidden_text_element:\n",
    "        hidden_text_html += (\"\\n\" + el.text)\n",
    "    \n",
    "    soup = BeautifulSoup(hidden_text_html, 'html.parser')\n",
    "    text = soup.get_text(separator='\\n').strip()\n",
    "    \n",
    "    # Replace multiple consecutive \"\\n\" with a single \"\\n\"\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    date = root.find(\".//NumericDate\").text\n",
    "    year, month = date.split(\"-\")[:2]\n",
    "    title = root.find(\".//SortTitle\").text\n",
    "    loc = root.find(\".//Qualifier\").text\n",
    "    \n",
    "    sentences = text_to_sentences(text).split(\"\\n\")  # Assuming text_to_sentences just splits by newlines\n",
    "    \n",
    "    total_sents += len(sentences)\n",
    "    inflation_sents = []\n",
    "    for sent in sentences:\n",
    "        if check_inflation(sent):\n",
    "            # inflation_sents += 1\n",
    "            inflation_sents.append(sent)\n",
    "            \n",
    "    file_id = file.split(\".\")[0]\n",
    "    \n",
    "    return none_text, total_sents, inflation_sents, f\"{year}-{month}\", file_id, title, loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlanta, Ga.Atlanta, Ga.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 248.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences processed: 40\n",
      "Total sentences mentioning inflation: 0\n",
      "Total files with no hidden text: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files = [file for file in os.listdir(base_data_dir) if file.endswith(\".xml\")]\n",
    "\n",
    "with Pool(cpu_count()) as pool:\n",
    "        results = list(tqdm(pool.imap(process_file, files), total=len(files)))\n",
    "    \n",
    "# Aggregate results\n",
    "none_text = sum(result[0] for result in results)\n",
    "total_sents = sum(result[1] for result in results)\n",
    "# inflation_sents = [res for result in results for res in result[2]]\n",
    "inflation_sents = [result[2] for result in results]\n",
    "# n_inflation_sents = len(inflation_sents)\n",
    "year_month = [result[3] for result in results]\n",
    "file_id = [result[4] for result in results]\n",
    "\n",
    "df = pd.DataFrame({\"file_id\": file_id, \"year_month\": year_month, \"text\": inflation_sents})\n",
    "df= df.explode(\"text\").reset_index(drop=True)\n",
    "df = df.dropna()\n",
    "\n",
    "file_path = f\"{out_dir}/test_sents.csv\"\n",
    "df.to_csv(file_path, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Total sentences processed: {total_sents}\")\n",
    "print(f\"Total sentences mentioning inflation: {len(df)}\")\n",
    "print(f\"Total files with no hidden text: {none_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mourad-econ-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
